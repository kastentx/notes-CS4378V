# Support Vector Machine
* popular in early deep learning research
* "supervised" learning method
  * given labels with data
* optimization objective: alternative view of logisitic regression
* to go from logistic regression to SVM:
  * set `C` equal to `1/lambda`
  * replace the `-log` term with cost function
* sometimes called a "large-margin classifier"
  * can define a higher/lower threshhold to achieve y=1 or y=0
* we want to find a large value for `p` and a small value for `Ɵ`

# Kernels
* Non-linear decision boundary
  * alternative to adding higher-order polynomial terms
* given x, compute a new feature based on distance to certain landmarks

## SVM Parameters
* Large C: lower bias, high variance
* Small C: High bias, low variance
* large sigma<sup>2</sup>: features vary more smoothly
* small sigma<sup>2</sup>: 

## Using SVM
* you can use SVM software packages to solve for `Ɵ`
* 